import time
from pyspark.sql import SparkSession
from pyspark.sql.functions import unix_timestamp, concat_ws, col
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml.classification import (
    LogisticRegression, DecisionTreeClassifier,
    RandomForestClassifier, LinearSVC
)
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml import Pipeline

# ========== 1. SparkSession ==========
spark = (
    SparkSession.builder
    .appName("SAML-D All Baseline Modes with TimeSeries Split")
    .config("spark.driver.memory", "30g")
    .config("spark.executor.memory", "20g")
    .config("spark.sql.shuffle.partitions", "200")
    .getOrCreate()
)
spark.conf.set("spark.sql.legacy.timeParserPolicy", "LEGACY")

# ========== 2. è®€å–è³‡æ–™ ==========
df_orig = spark.read.parquet(
    r"C:\Users\Leon\Desktop\ç¨‹å¼èªè¨€è³‡æ–™\python\UF-FAE\Anti Money Laundering Transaction Data (SAML-D)\SAML-D.parquet"
)

df_graph = spark.read.parquet(
    r"C:\Users\Leon\Desktop\ç¨‹å¼èªè¨€è³‡æ–™\python\UF-FAE\Anti Money Laundering Transaction Data (SAML-D)\SAML-D_with_graph_centrality.parquet"
)

# ========== 3. åŠ  timestamp ==========
def add_ts(df):
    return df.withColumn(
        "timestamp",
        unix_timestamp(concat_ws(" ", col("Date"), col("Time")), "yyyy-MM-dd HH:mm:ss").cast("long")
    )

df_orig = add_ts(df_orig)
df_graph = add_ts(df_graph)

# ========== 4. æ™‚é–“åˆ‡åˆ† ==========
df_orig = df_orig.orderBy("timestamp")
df_graph = df_graph.orderBy("timestamp")

total = df_orig.count()
split_idx = int(total * 0.8)
boundary_ts = df_orig.select("timestamp").take(split_idx)[-1][0]

train_orig = df_orig.filter(col("timestamp") <= boundary_ts)
test_orig  = df_orig.filter(col("timestamp") > boundary_ts)

train_graph = df_graph.filter(col("timestamp") <= boundary_ts)
test_graph  = df_graph.filter(col("timestamp") > boundary_ts)

# ========== 5. Baseline ä¸‰ç¨®æ¨¡å¼ ==========
modes = {
    "ç´”åŸç”Ÿæ¬„ä½": {
        "train": train_orig,
        "test": test_orig,
        "categorical": [
            "Payment_currency",
            "Received_currency",
            "Sender_bank_location",
            "Receiver_bank_location",
            "Payment_type"
        ],
        "numeric": ["Amount"]
    },
    "ç´”åœ–è«–æ¬„ä½": {
        "train": train_graph,
        "test": test_graph,
        "categorical": [],
        "numeric": [
            "group_node_count", "group_edge_count", "group_bidirect_ratio",
            "sender_degree", "receiver_degree",
            "sender_closeness", "receiver_closeness",
            "sender_betweenness", "receiver_betweenness"
        ]
    },
    "å¤šæ¨¡æ…‹ï¼ˆåŸç”Ÿ+åœ–è«–ï¼‰": {
        "train": train_graph,
        "test": test_graph,
        "categorical": [
            "Payment_currency",
            "Received_currency",
            "Sender_bank_location",
            "Receiver_bank_location",
            "Payment_type"
        ],
        "numeric": [
            "Amount",
            "group_node_count", "group_edge_count", "group_bidirect_ratio",
            "sender_degree", "receiver_degree",
            "sender_closeness", "receiver_closeness",
            "sender_betweenness", "receiver_betweenness"
        ]
    }
}

# ========== 6. æ¨¡å‹ ==========
models = {
    "Logistic Regression": LogisticRegression(labelCol="Is_laundering", featuresCol="features"),
    "Decision Tree": DecisionTreeClassifier(labelCol="Is_laundering", featuresCol="features"),
    "Random Forest": RandomForestClassifier(labelCol="Is_laundering", featuresCol="features", numTrees=100),
    "SVM (LinearSVC)": LinearSVC(labelCol="Is_laundering", featuresCol="features")
}

# ========== 7. æŒ‡æ¨™ ==========
def evaluate_metrics(pred):
    auc = BinaryClassificationEvaluator(labelCol="Is_laundering", metricName="areaUnderROC").evaluate(pred)
    p = MulticlassClassificationEvaluator(labelCol="Is_laundering", metricName="weightedPrecision").evaluate(pred)
    r = MulticlassClassificationEvaluator(labelCol="Is_laundering", metricName="weightedRecall").evaluate(pred)
    f1 = MulticlassClassificationEvaluator(labelCol="Is_laundering", metricName="f1").evaluate(pred)
    return auc, p, r, f1

def eval_cls(pred, cls):
    prec = MulticlassClassificationEvaluator(
        labelCol="Is_laundering", metricName="precisionByLabel"
    ).setMetricLabel(cls).evaluate(pred)

    rec = MulticlassClassificationEvaluator(
        labelCol="Is_laundering", metricName="recallByLabel"
    ).setMetricLabel(cls).evaluate(pred)

    f1 = (2 * prec * rec / (prec + rec)) if (prec + rec) > 0 else 0
    return prec, rec, f1


# ========== 8. ä¸»è¿´åœˆï¼ˆè‡ªå‹•è·‘ä¸‰ç¨® Baselineï¼‰==========
print("\n=======================================")
print("ğŸ”¥ã€ä¸‰å¤§ Baseline æ¨¡å¼é–‹å§‹ â€” Ablation Studyã€‘")
print("=======================================\n")

for mode_name, cfg in modes.items():

    print("\n=======================================")
    print(f"ğŸŸ© æ¨¡å¼ï¼š{mode_name}")
    print("=======================================\n")

    train_df = cfg["train"]
    test_df = cfg["test"]
    cat_cols = cfg["categorical"]
    num_cols = cfg["numeric"]

    indexers = [StringIndexer(inputCol=c, outputCol=f"{c}_idx", handleInvalid="keep") for c in cat_cols]
    encoders = [OneHotEncoder(inputCol=f"{c}_idx", outputCol=f"{c}_vec") for c in cat_cols]
    feature_cols = num_cols + [f"{c}_vec" for c in cat_cols]

    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

    for model_name, clf in models.items():
        print(f"\nğŸ”¹ã€{mode_name} | {model_name}ã€‘")

        stages = indexers + encoders + [assembler, clf] if cat_cols else [assembler, clf]
        pipeline = Pipeline(stages=stages)

        start = time.time()
        model = pipeline.fit(train_df)
        preds = model.transform(test_df)
        elapsed = time.time() - start

        auc, p_w, r_w, f1_w = evaluate_metrics(preds)

        print(f"   ğŸ•’ è¨“ç·´+é æ¸¬æ™‚é–“   ï¼š{elapsed:.2f} ç§’")
        print(f"   ğŸ“ˆ AUC(ROC)        ï¼š{auc:.4f}")
        print(f"   ğŸ¯ Weighted Precisionï¼š{p_w:.4f}")
        print(f"   ğŸ¯ Weighted Recall   ï¼š{r_w:.4f}")
        print(f"   ğŸ§® Weighted F1 Score ï¼š{f1_w:.4f}")

        for cls in [0.0, 1.0]:
            pr, rc, f1 = eval_cls(preds, cls)
            print(f"   ğŸ”¹ Class {int(cls)} â€” Precision: {pr:.4f}, Recall: {rc:.4f}, F1: {f1:.4f}")

print("\nğŸ‰ã€ä¸‰å¤§ Baseline å…¨éƒ¨å®Œæˆ â€” å¯ç›´æ¥å°ç…§ UF-FAEã€‘")
